{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 - Assignment Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes the LAB-2 assignment of the Text Mining course. It is about sentiment analysis.\n",
    "\n",
    "The aims of the assignment are:\n",
    "* Learn how to run a rule-based sentiment analysis module (VADER)\n",
    "* Learn how to run a machine learning sentiment analysis module (Scikit-Learn/ Naive Bayes)\n",
    "* Learn how to run scikit-learn metrics for the quantitative evaluation\n",
    "* Learn how to perform and interpret a quantitative evaluation of the outcomes of the tools (in terms of Precision, Recall, and F<sub>1</sub>)\n",
    "* Learn how to evaluate the results qualitatively (by examining the data) \n",
    "* Get insight into differences between the two applied methods\n",
    "* Get insight into the effects of using linguistic preprocessing\n",
    "* Be able to describe differences between the two methods in terms of their results\n",
    "* Get insight into issues when applying these methods across different  domains\n",
    "\n",
    "In this assignment, you are going to create your own gold standard set from 50 tweets. You will the VADER and scikit-learn classifiers to these tweets and evaluate the results by using evaluation metrics and inspecting the data.\n",
    "\n",
    "We recommend you go through the notebooks in the following order:\n",
    "* **Read the assignment (see below)**\n",
    "* **Lab3.2-Sentiment-analysis-with-VADER.ipynb**\n",
    "* **Lab3.3-Sentiment-analysis.with-scikit-learn.ipynb**\n",
    "* **Answer the questions of the assignment (see below) using the provided notebooks and submit**\n",
    "\n",
    "In this assignment you are asked to perform both quantitative evaluations and error analyses:\n",
    "* a quantitative evaluation concerns the scores (Precision, Recall, and F<sub>1</sub>) provided by scikit's classification_report. It includes the scores per category, as well as micro and macro averages. Discuss whether the scores are balanced or not between the different categories (positive, negative, neutral) and between precision and recall. Discuss the shortcomings (if any) of the classifier based on these scores\n",
    "* an error analysis regarding the misclassifications of the classifier. It involves going through the texts and trying to understand what has gone wrong. It servers to get insight in what could be done to improve the performance of the classifier. Do you observe patterns in misclassifications?  Discuss why these errors are made and propose ways to solve them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "The notebooks in this block have been originally created by [Marten Postma](https://martenpostma.github.io) and [Isa Maks](https://research.vu.nl/en/persons/e-maks). Adaptations were made by [Filip Ilievski](http://ilievski.nl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: VADER assignments\n",
    "\n",
    "\n",
    "### Preparation (nothing to submit):\n",
    "To be able to answer the VADER questions you need to know how the tool works. \n",
    "* Read more about the VADER tool in [this blog](http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html).  \n",
    "* VADER provides 4 scores (positive, negative, neutral, compound). Be sure to understand what they mean and how they are calculated.\n",
    "* VADER uses rules to handle linguistic phenomena such as negation and intensification. Be sure to understand which rules are used, how they work, and why they are important.\n",
    "* VADER makes use of a sentiment lexicon. Have a look at the lexicon. Be sure to understand which information can be found there (lemma?, wordform?, part-of-speech?, polarity value?, word meaning?) What do all scores mean? https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt) \n",
    "\n",
    "\n",
    "### [3.5 points] Question1:\n",
    "\n",
    "Regard the following sentences and their output as given by VADER. Regard sentences 1 to 7, and explain the outcome **for each sentence**. Take into account both the rules applied by VADER and the lexicon that is used. You will find that some of the results are reasonable, but others are not. Explain what is going wrong or not when correct and incorrect results are produced. \n",
    "\n",
    "```\n",
    "INPUT SENTENCE 1 I love apples\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.192, 'pos': 0.808, 'compound': 0.6369}\n",
    "\n",
    "INPUT SENTENCE 2 I don't love apples\n",
    "VADER OUTPUT {'neg': 0.627, 'neu': 0.373, 'pos': 0.0, 'compound': -0.5216}\n",
    "\n",
    "INPUT SENTENCE 3 I love apples :-)\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.133, 'pos': 0.867, 'compound': 0.7579}\n",
    "\n",
    "INPUT SENTENCE 4 These houses are ruins\n",
    "VADER OUTPUT {'neg': 0.492, 'neu': 0.508, 'pos': 0.0, 'compound': -0.4404}\n",
    "\n",
    "INPUT SENTENCE 5 These houses are certainly not considered ruins\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.51, 'pos': 0.49, 'compound': 0.5867}\n",
    "\n",
    "INPUT SENTENCE 6 He lies in the chair in the garden\n",
    "VADER OUTPUT {'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'compound': -0.4215}\n",
    "\n",
    "INPUT SENTENCE 7 This house is like any house\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.3612}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "- Input 1 : I think that this is correct because the score is above 0.45 for the positive sentiment category. There is a slight neutrality score which seems appropriate.\n",
    "- Input 2 : This is also correct as there is mainly a negative sentiment score and slight neutrality.\n",
    "- Input 3 : This is also correct as unlike Input 1 it has a smiley emoji which would mean that it is more positive.\n",
    "- Input 4 : I think that this should have a more negative sentiment than neutral.\n",
    "- Input 5 : I think that this is right because \"Certainly not\" does make it more positive.\n",
    "- Input 6 : I think that this is wrong because \"lies\" in this context means laying down and not \"lying\".So it should be more neutral.\n",
    "- Input 7 : This could technically be negative because it could be sarcasm.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Points: 2.5] Exercise 2: Collecting 50 tweets for evaluation\n",
    "Collect 50 tweets. Try to find tweets that are interesting for sentiment analysis, e.g., very positive, neutral, and negative tweets. These could be your own tweets (typed in) or collected from the Twitter stream.\n",
    "\n",
    "We will store the tweets in the file **my_tweets.json** (use a text editor to edit).\n",
    "For each tweet, you should insert:\n",
    "* sentiment analysis label: negative | neutral | positive (this you determine yourself, this is not done by a computer)\n",
    "* the text of the tweet\n",
    "* the Tweet-URL\n",
    "\n",
    "from:\n",
    "```\n",
    "    \"1\": {\n",
    "        \"sentiment_label\": \"\",\n",
    "        \"text_of_tweet\": \"\",\n",
    "        \"tweet_url\": \"\",\n",
    "```\n",
    "to:\n",
    "```\n",
    "\"1\": {\n",
    "        \"sentiment_label\": \"positive\",\n",
    "        \"text_of_tweet\": \"All across America people chose to get involved, get engaged and stand up. Each of us can make a difference, and all of us ought to try. So go keep changing the world in 2018.\",\n",
    "        \"tweet_url\" : \"https://twitter.com/BarackObama/status/946775615893655552\",\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load your tweets with human annotation in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tweets = json.load(open('my_tweets.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_, tweet_info in my_tweets.items():\n",
    "    print(id_, tweet_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5 points] Question 3:\n",
    "\n",
    "Run VADER on your own tweets (see function **run_vader** from notebook **Lab2-Sentiment-analysis-using-VADER.ipynb**). You can use the code snippet below this explanation as a starting point. \n",
    "* [2.5 points] a. Perform a quantitative evaluation. Explain the different scores, and explain which scores are most relevant and why.\n",
    "* [2.5 points] b. Perform an error analysis: select 10 positive, 10 negative and 10 neutral tweets that are not correctly classified and try to understand why. Refer to the VADER-rules and the VADER-lexicon. Of course, if there are less than 10 errors for a category, you only have to check those. For example, if there are only 5 errors for positive tweets, you just describe those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.sentiment import vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "vader_model = SentimentIntensityAnalyzer()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_vader(textual_unit,\n",
    "              lemmatize=False,\n",
    "              parts_of_speech_to_consider=None,\n",
    "              verbose=0):\n",
    "    \"\"\"\n",
    "    Run VADER on a sentence from spacy\n",
    "\n",
    "    :param str textual unit: a textual unit, e.g., sentence, sentences (one string)\n",
    "    (by looping over doc.sents)\n",
    "    :param bool lemmatize: If True, provide lemmas to VADER instead of words\n",
    "    :param set parts_of_speech_to_consider:\n",
    "    -None or empty set: all parts of speech are provided\n",
    "    -non-empty set: only these parts of speech are considered.\n",
    "    :param int verbose: if set to 1, information is printed\n",
    "    about input and output\n",
    "\n",
    "    :rtype: dict\n",
    "    :return: vader output dict\n",
    "    \"\"\"\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(textual_unit)\n",
    "\n",
    "    input_to_vader = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "\n",
    "            to_add = token.text\n",
    "\n",
    "            if lemmatize:\n",
    "                to_add = token.lemma_\n",
    "\n",
    "                if to_add == '-PRON-':\n",
    "                    to_add = token.text\n",
    "\n",
    "            if parts_of_speech_to_consider:\n",
    "                if token.pos_ in parts_of_speech_to_consider:\n",
    "                    input_to_vader.append(to_add)\n",
    "            else:\n",
    "                input_to_vader.append(to_add)\n",
    "\n",
    "    scores = vader_model.polarity_scores(' '.join(input_to_vader))\n",
    "\n",
    "\n",
    "    return scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_output_to_label(vader_output):\n",
    "    \"\"\"\n",
    "    map vader output e.g.,\n",
    "    {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
    "    to one of the following values:\n",
    "    a) positive float -> 'positive'\n",
    "    b) 0.0 -> 'neutral'\n",
    "    c) negative float -> 'negative'\n",
    "    \n",
    "    :param dict vader_output: output dict from vader\n",
    "    \n",
    "    :rtype: str\n",
    "    :return: 'negative' | 'neutral' | 'positive'\n",
    "    \"\"\"\n",
    "    compound = vader_output['compound']\n",
    "    \n",
    "    if compound < 0:\n",
    "        return 'negative'\n",
    "    elif compound == 0.0:\n",
    "        return 'neutral'\n",
    "    elif compound > 0.0:\n",
    "        return 'positive'\n",
    "    \n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.0}) == 'neutral'\n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.01}) == 'positive'\n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': -0.01}) == 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "# settings (to change for different experiments)\n",
    "to_lemmatize = True \n",
    "pos = set()\n",
    "\n",
    "for id_, tweet_info in my_tweets.items():\n",
    "    the_tweet = tweet_info['text_of_tweet']\n",
    "    vader_output = run_vader(the_tweet)\n",
    "    vader_label = vader_output_to_label(vader_output)# convert vader output to category\n",
    "    tweets.append(the_tweet)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(tweet_info['sentiment_label'])\n",
    "    \n",
    "\n",
    "# use scikit-learn's classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(gold, all_vader_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quantitative evaluation:\n",
    "\n",
    "* Precision: The precision is intuitively the ability of the classifier not to label as positive a sample that is negative. The best value is 1 and the worst value is 0.\n",
    "*\n",
    "* Recall: The recall is intuitively the ability of the classifier to find all the positive samples. The best value is 1 and the worst value is 0.\n",
    "\n",
    "* F1-score: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal.\n",
    "\n",
    "* Support: The support is the number of occurrences of each class in y_true.\n",
    "\n",
    "* Accuracy: The accuracy is the number of correctly classified samples divided by the total number of samples. The best value is 1 and the worst value is 0.\n",
    "\n",
    "* Macro avg: Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "* Weighted avg: Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "\n",
    "* Micro avg: Calculate metrics globally by counting the total true positives, false negatives and false positives. This is a better metric when we have class imbalance.\n",
    "\n",
    "* Samples avg: Calculate metrics for each instance, and find their average (only meaningful for multilabel classification where this differs from accuracy_score).\n",
    "*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# error analysis\n",
    "misclassified_pos = []\n",
    "misclassified_neg = []\n",
    "misclassified_neu = []\n",
    "\n",
    "for i, (tweet, vader_label, gold_label) in enumerate(zip(tweets, all_vader_output, gold)):\n",
    "    if vader_label != gold_label:\n",
    "        if gold_label == 'positive':\n",
    "            misclassified_pos.append((i, tweet, vader_label, gold_label))\n",
    "        elif gold_label == 'negative':\n",
    "            misclassified_neg.append((i, tweet, vader_label, gold_label))\n",
    "        elif gold_label == 'neutral':\n",
    "            misclassified_neu.append((i, tweet, vader_label, gold_label))\n",
    "\n",
    "print('Number of misclassified positive tweets: {}'.format(len(misclassified_pos)))\n",
    "print('Number of misclassified negative tweets: {}'.format(len(misclassified_neg)))\n",
    "print('Number of misclassified neutral tweets: {}'.format(len(misclassified_neu)))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print misclassified positive tweets\n",
    "for i, tweet, vader_label, gold_label in misclassified_pos:\n",
    "    print('Tweet: {}'.format(tweet))\n",
    "    print('Vader label: {}'.format(vader_label))\n",
    "    print('Gold label: {}'.format(gold_label))\n",
    "    print('-----------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Error Analysis on Positive Tweets:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print misclassified negative tweets\n",
    "for i, tweet, vader_label, gold_label in misclassified_neg:\n",
    "    print('Tweet: {}'.format(tweet))\n",
    "    print('Vader label: {}'.format(vader_label))\n",
    "    print('Gold label: {}'.format(gold_label))\n",
    "    print('-----------------------------')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Error Analysis on Negative Tweets:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print misclassified neutral tweets\n",
    "for i, tweet, vader_label, gold_label in misclassified_neu:\n",
    "    print('Tweet: {}'.format(tweet))\n",
    "    print('Vader label: {}'.format(vader_label))\n",
    "    print('Gold label: {}'.format(gold_label))\n",
    "    print('-----------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Error Analysis on Neutral Tweets:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4 points] Question 4:\n",
    "Run VADER on the set of airline tweets with the following settings:\n",
    "\n",
    "* Run VADER (as it is) on the set of airline tweets \n",
    "* Run VADER on the set of airline tweets after having lemmatized the text\n",
    "* Run VADER on the set of airline tweets with only adjectives\n",
    "* Run VADER on the set of airline tweets with only adjectives and after having lemmatized the text\n",
    "* Run VADER on the set of airline tweets with only nouns\n",
    "* Run VADER on the set of airline tweets with only nouns and after having lemmatized the text\n",
    "* Run VADER on the set of airline tweets with only verbs\n",
    "* Run VADER on the set of airline tweets with only verbs and after having lemmatized the text\n",
    "\n",
    "* [1 point] a. Generate for all separate experiments the classification report, i.e., Precision, Recall, and F<sub>1</sub> scores per category as well as micro and macro averages. **Use a different code cell (or multiple code cells) for each experiment.**\n",
    "* [3 points] b. Compare the scores and explain what they tell you.\n",
    "* - Does lemmatisation help? Explain why or why not.\n",
    "* - Are all parts of speech equally important for sentiment analysis? Explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from sklearn.datasets import load_files\n",
    "cwd = pathlib.Path.cwd()\n",
    "airline_tweets_folder = cwd.joinpath('airlinetweets')\n",
    "airline_tweets_train = load_files(str(airline_tweets_folder))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run vader on the set of airline tweets\n",
    "tweets = []\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "for i, tweet in enumerate(airline_tweets_train.data[:100]):\n",
    "    tweets.append(tweet.decode('utf-8'))\n",
    "    vader_output = run_vader(tweet.decode('utf-8'))\n",
    "    vader_label = vader_output_to_label(vader_output)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(airline_tweets_train.target_names[airline_tweets_train.target[i]])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"VADER (as it is) on the set of airline tweets Classification Report\")\n",
    "print(classification_report(gold, all_vader_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m gold \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, tweet \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(airline_tweets_train\u001B[38;5;241m.\u001B[39mdata):\n\u001B[0;32m----> 6\u001B[0m     vader_output \u001B[38;5;241m=\u001B[39m \u001B[43mrun_vader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtweet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlemmatize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     vader_label \u001B[38;5;241m=\u001B[39m vader_output_to_label(vader_output)\n\u001B[1;32m      8\u001B[0m     all_vader_output\u001B[38;5;241m.\u001B[39mappend(vader_label)\n",
      "Cell \u001B[0;32mIn[33], line 20\u001B[0m, in \u001B[0;36mrun_vader\u001B[0;34m(textual_unit, lemmatize, parts_of_speech_to_consider, verbose)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_vader\u001B[39m(textual_unit,\n\u001B[1;32m      2\u001B[0m               lemmatize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m      3\u001B[0m               parts_of_speech_to_consider\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m      4\u001B[0m               verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m      5\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m    Run VADER on a sentence from spacy\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m    :return: vader output dict\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m     nlp \u001B[38;5;241m=\u001B[39m \u001B[43mspacy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43men_core_web_sm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     doc \u001B[38;5;241m=\u001B[39m nlp(textual_unit)\n\u001B[1;32m     23\u001B[0m     input_to_vader \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/spacy/__init__.py:51\u001B[0m, in \u001B[0;36mload\u001B[0;34m(name, vocab, disable, exclude, config)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\n\u001B[1;32m     31\u001B[0m     name: Union[\u001B[38;5;28mstr\u001B[39m, Path],\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m     config: Union[Dict[\u001B[38;5;28mstr\u001B[39m, Any], Config] \u001B[38;5;241m=\u001B[39m util\u001B[38;5;241m.\u001B[39mSimpleFrozenDict(),\n\u001B[1;32m     37\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Language:\n\u001B[1;32m     38\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \n\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m    name (str): Package name or model path.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/spacy/util.py:420\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(name, vocab, disable, exclude, config)\u001B[0m\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_lang_class(name\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblank:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m))()\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_package(name):  \u001B[38;5;66;03m# installed as package\u001B[39;00m\n\u001B[0;32m--> 420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_model_from_package\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m Path(name)\u001B[38;5;241m.\u001B[39mexists():  \u001B[38;5;66;03m# path to model data directory\u001B[39;00m\n\u001B[1;32m    422\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m load_model_from_path(Path(name), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/spacy/util.py:453\u001B[0m, in \u001B[0;36mload_model_from_package\u001B[0;34m(name, vocab, disable, exclude, config)\u001B[0m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Load a model from an installed package.\u001B[39;00m\n\u001B[1;32m    439\u001B[0m \n\u001B[1;32m    440\u001B[0m \u001B[38;5;124;03mname (str): The package name.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;124;03mRETURNS (Language): The loaded nlp object.\u001B[39;00m\n\u001B[1;32m    451\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(name)\n\u001B[0;32m--> 453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/en_core_web_sm/__init__.py:10\u001B[0m, in \u001B[0;36mload\u001B[0;34m(**overrides)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moverrides):\n\u001B[0;32m---> 10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_model_from_init_py\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;18;43m__file__\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moverrides\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/spacy/util.py:619\u001B[0m, in \u001B[0;36mload_model_from_init_py\u001B[0;34m(init_file, vocab, disable, exclude, config)\u001B[0m\n\u001B[1;32m    617\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_path\u001B[38;5;241m.\u001B[39mexists():\n\u001B[1;32m    618\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE052\u001B[38;5;241m.\u001B[39mformat(path\u001B[38;5;241m=\u001B[39mdata_path))\n\u001B[0;32m--> 619\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_model_from_path\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    620\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    621\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    624\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    625\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    626\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/spacy/util.py:488\u001B[0m, in \u001B[0;36mload_model_from_path\u001B[0;34m(model_path, meta, vocab, disable, exclude, config)\u001B[0m\n\u001B[1;32m    486\u001B[0m overrides \u001B[38;5;241m=\u001B[39m dict_to_dot(config)\n\u001B[1;32m    487\u001B[0m config \u001B[38;5;241m=\u001B[39m load_config(config_path, overrides\u001B[38;5;241m=\u001B[39moverrides)\n\u001B[0;32m--> 488\u001B[0m nlp \u001B[38;5;241m=\u001B[39m \u001B[43mload_model_from_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m nlp\u001B[38;5;241m.\u001B[39mfrom_disk(model_path, exclude\u001B[38;5;241m=\u001B[39mexclude, overrides\u001B[38;5;241m=\u001B[39moverrides)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/spacy/util.py:528\u001B[0m, in \u001B[0;36mload_model_from_config\u001B[0;34m(config, meta, vocab, disable, exclude, auto_fill, validate)\u001B[0m\n\u001B[1;32m    525\u001B[0m \u001B[38;5;66;03m# This will automatically handle all codes registered via the languages\u001B[39;00m\n\u001B[1;32m    526\u001B[0m \u001B[38;5;66;03m# registry, including custom subclasses provided via entry points\u001B[39;00m\n\u001B[1;32m    527\u001B[0m lang_cls \u001B[38;5;241m=\u001B[39m get_lang_class(nlp_config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlang\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m--> 528\u001B[0m nlp \u001B[38;5;241m=\u001B[39m \u001B[43mlang_cls\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    529\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    530\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    532\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    533\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauto_fill\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauto_fill\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    534\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    535\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    536\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m nlp\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/spacy/language.py:1809\u001B[0m, in \u001B[0;36mLanguage.from_config\u001B[0;34m(cls, config, vocab, disable, exclude, meta, auto_fill, validate)\u001B[0m\n\u001B[1;32m   1806\u001B[0m     factory \u001B[38;5;241m=\u001B[39m pipe_cfg\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfactory\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1807\u001B[0m     \u001B[38;5;66;03m# The pipe name (key in the config) here is the unique name\u001B[39;00m\n\u001B[1;32m   1808\u001B[0m     \u001B[38;5;66;03m# of the component, not necessarily the factory\u001B[39;00m\n\u001B[0;32m-> 1809\u001B[0m     \u001B[43mnlp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_pipe\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1810\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfactory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1811\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpipe_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1812\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpipe_cfg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1813\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1814\u001B[0m \u001B[43m        \u001B[49m\u001B[43mraw_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mraw_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1815\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1816\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1817\u001B[0m     \u001B[38;5;66;03m# We need the sourced components to reference the same\u001B[39;00m\n\u001B[1;32m   1818\u001B[0m     \u001B[38;5;66;03m# vocab without modifying the current vocab state **AND**\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1823\u001B[0m     \u001B[38;5;66;03m# during deserialization, so they do not need any\u001B[39;00m\n\u001B[1;32m   1824\u001B[0m     \u001B[38;5;66;03m# additional handling.\u001B[39;00m\n\u001B[1;32m   1825\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m vocab_b \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/spacy/language.py:795\u001B[0m, in \u001B[0;36mLanguage.add_pipe\u001B[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001B[0m\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhas_factory(factory_name):\n\u001B[1;32m    788\u001B[0m         err \u001B[38;5;241m=\u001B[39m Errors\u001B[38;5;241m.\u001B[39mE002\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    789\u001B[0m             name\u001B[38;5;241m=\u001B[39mfactory_name,\n\u001B[1;32m    790\u001B[0m             opts\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfactory_names),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    793\u001B[0m             lang_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlang,\n\u001B[1;32m    794\u001B[0m         )\n\u001B[0;32m--> 795\u001B[0m     pipe_component \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_pipe\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfactory_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m        \u001B[49m\u001B[43mraw_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mraw_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    801\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    802\u001B[0m pipe_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_pipe_index(before, after, first, last)\n\u001B[1;32m    803\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pipe_meta[name] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_factory_meta(factory_name)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/spacy/language.py:675\u001B[0m, in \u001B[0;36mLanguage.create_pipe\u001B[0;34m(self, factory_name, name, config, raw_config, validate)\u001B[0m\n\u001B[1;32m    672\u001B[0m \u001B[38;5;66;03m# We're calling the internal _fill here to avoid constructing the\u001B[39;00m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;66;03m# registered functions twice\u001B[39;00m\n\u001B[1;32m    674\u001B[0m resolved \u001B[38;5;241m=\u001B[39m registry\u001B[38;5;241m.\u001B[39mresolve(cfg, validate\u001B[38;5;241m=\u001B[39mvalidate)\n\u001B[0;32m--> 675\u001B[0m filled \u001B[38;5;241m=\u001B[39m \u001B[43mregistry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfill\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcfg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfactory_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcfg\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    676\u001B[0m filled \u001B[38;5;241m=\u001B[39m Config(filled)\n\u001B[1;32m    677\u001B[0m filled[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfactory\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m factory_name\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/thinc/config.py:760\u001B[0m, in \u001B[0;36mregistry.fill\u001B[0;34m(cls, config, schema, overrides, validate)\u001B[0m\n\u001B[1;32m    751\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    752\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfill\u001B[39m(\n\u001B[1;32m    753\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    758\u001B[0m     validate: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    759\u001B[0m ):\n\u001B[0;32m--> 760\u001B[0m     _, filled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    761\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moverrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverrides\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresolve\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m    762\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    763\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m filled\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/thinc/config.py:795\u001B[0m, in \u001B[0;36mregistry._make\u001B[0;34m(cls, config, schema, overrides, resolve, validate)\u001B[0m\n\u001B[1;32m    793\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interpolated:\n\u001B[1;32m    794\u001B[0m     config \u001B[38;5;241m=\u001B[39m Config(orig_config)\u001B[38;5;241m.\u001B[39minterpolate()\n\u001B[0;32m--> 795\u001B[0m filled, _, resolved \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fill\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moverrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverrides\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresolve\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresolve\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    798\u001B[0m filled \u001B[38;5;241m=\u001B[39m Config(filled, section_order\u001B[38;5;241m=\u001B[39msection_order)\n\u001B[1;32m    799\u001B[0m \u001B[38;5;66;03m# Check that overrides didn't include invalid properties not in config\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/thinc/config.py:850\u001B[0m, in \u001B[0;36mregistry._fill\u001B[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001B[0m\n\u001B[1;32m    848\u001B[0m     schema\u001B[38;5;241m.\u001B[39m__fields__[key] \u001B[38;5;241m=\u001B[39m copy_model_field(field, Any)\n\u001B[1;32m    849\u001B[0m promise_schema \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mmake_promise_schema(value, resolve\u001B[38;5;241m=\u001B[39mresolve)\n\u001B[0;32m--> 850\u001B[0m filled[key], validation[v_key], final[key] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fill\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpromise_schema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresolve\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresolve\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_parent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43moverrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    858\u001B[0m reg_name, func_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mget_constructor(final[key])\n\u001B[1;32m    859\u001B[0m args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mparse_args(final[key])\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/thinc/config.py:850\u001B[0m, in \u001B[0;36mregistry._fill\u001B[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001B[0m\n\u001B[1;32m    848\u001B[0m     schema\u001B[38;5;241m.\u001B[39m__fields__[key] \u001B[38;5;241m=\u001B[39m copy_model_field(field, Any)\n\u001B[1;32m    849\u001B[0m promise_schema \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mmake_promise_schema(value, resolve\u001B[38;5;241m=\u001B[39mresolve)\n\u001B[0;32m--> 850\u001B[0m filled[key], validation[v_key], final[key] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fill\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpromise_schema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresolve\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresolve\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_parent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43moverrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    858\u001B[0m reg_name, func_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mget_constructor(final[key])\n\u001B[1;32m    859\u001B[0m args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mparse_args(final[key])\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/thinc/config.py:849\u001B[0m, in \u001B[0;36mregistry._fill\u001B[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001B[0m\n\u001B[1;32m    847\u001B[0m     field \u001B[38;5;241m=\u001B[39m schema\u001B[38;5;241m.\u001B[39m__fields__[key]\n\u001B[1;32m    848\u001B[0m     schema\u001B[38;5;241m.\u001B[39m__fields__[key] \u001B[38;5;241m=\u001B[39m copy_model_field(field, Any)\n\u001B[0;32m--> 849\u001B[0m promise_schema \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_promise_schema\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresolve\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresolve\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    850\u001B[0m filled[key], validation[v_key], final[key] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_fill(\n\u001B[1;32m    851\u001B[0m     value,\n\u001B[1;32m    852\u001B[0m     promise_schema,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    856\u001B[0m     overrides\u001B[38;5;241m=\u001B[39moverrides,\n\u001B[1;32m    857\u001B[0m )\n\u001B[1;32m    858\u001B[0m reg_name, func_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mget_constructor(final[key])\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/thinc/config.py:1057\u001B[0m, in \u001B[0;36mregistry.make_promise_schema\u001B[0;34m(cls, obj, resolve)\u001B[0m\n\u001B[1;32m   1055\u001B[0m         sig_args[name] \u001B[38;5;241m=\u001B[39m (annotation, default)\n\u001B[1;32m   1056\u001B[0m sig_args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__config__\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m _PromiseSchemaConfig\n\u001B[0;32m-> 1057\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcreate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mArgModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msig_args\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/pydantic/main.py:1026\u001B[0m, in \u001B[0;36mpydantic.main.create_model\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/pydantic/main.py:179\u001B[0m, in \u001B[0;36mpydantic.main.ModelMetaclass.__new__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/site-packages/pydantic/typing.py:399\u001B[0m, in \u001B[0;36mpydantic.typing.resolve_annotations\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Text-Mining/lib/python3.9/typing.py:285\u001B[0m, in \u001B[0;36m_eval_type\u001B[0;34m(t, globalns, localns, recursive_guard)\u001B[0m\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m decorator(func)\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m decorator\n\u001B[0;32m--> 285\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_eval_type\u001B[39m(t, globalns, localns, recursive_guard\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfrozenset\u001B[39m()):\n\u001B[1;32m    286\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Evaluate all forward references in the given type t.\u001B[39;00m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;124;03m    For use of globalns and localns see the docstring for get_type_hints().\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;124;03m    recursive_guard is used to prevent infinite recursion with a recursive\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;124;03m    ForwardRef.\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    291\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, ForwardRef):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# run vader on the set of airline tweets after having lemmatized the text\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "for i, tweet in enumerate(airline_tweets_train.data[:100]):\n",
    "    vader_output = run_vader(tweet.decode('utf-8'), lemmatize=True)\n",
    "    vader_label = vader_output_to_label(vader_output)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(airline_tweets_train.target_names[airline_tweets_train.target[i]])\n",
    "\n",
    "\n",
    "print(\"VADER on the set of airline tweets after having lemmatized the text Classification Report\")\n",
    "print(classification_report(gold, all_vader_output))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run vader on the set of airline tweets with only adjectives\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "for i, tweet in enumerate(airline_tweets_train.data[:100]):\n",
    "    vader_output = run_vader(tweet.decode('utf-8'), parts_of_speech_to_consider={'ADJ'})\n",
    "    vader_label = vader_output_to_label(vader_output)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(airline_tweets_train.target_names[airline_tweets_train.target[i]])\n",
    "\n",
    "\n",
    "print(\"VADER on the set of airline tweets with only adjectives Classification Report\")\n",
    "print(classification_report(gold, all_vader_output))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run vader on the set of airline tweets with only adjectives and after having lemmatized the text\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "for i, tweet in enumerate(airline_tweets_train.data[:100]):\n",
    "    vader_output = run_vader(tweet.decode('utf-8'), parts_of_speech_to_consider={'ADJ'}, lemmatize=True)\n",
    "    vader_label = vader_output_to_label(vader_output)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(airline_tweets_train.target_names[airline_tweets_train.target[i]])\n",
    "\n",
    "\n",
    "print(\"VADER on the set of airline tweets with only adjectives and after having lemmatized the text Classification Report\")\n",
    "print(classification_report(gold, all_vader_output))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run vader on the set of airline tweets with only nouns\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "for i, tweet in enumerate(airline_tweets_train.data[:100]):\n",
    "    vader_output = run_vader(tweet.decode('utf-8'), parts_of_speech_to_consider={'NOUN'})\n",
    "    vader_label = vader_output_to_label(vader_output)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(airline_tweets_train.target_names[airline_tweets_train.target[i]])\n",
    "\n",
    "\n",
    "print(\"VADER on the set of airline tweets with only nouns Classification Report\")\n",
    "print(classification_report(gold, all_vader_output))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run vader on the set of airline tweets with only nouns and after having lemmatized the text\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "for i, tweet in enumerate(airline_tweets_train.data[:100]):\n",
    "    vader_output = run_vader(tweet.decode('utf-8'), parts_of_speech_to_consider={'NOUN'}, lemmatize=True)\n",
    "    vader_label = vader_output_to_label(vader_output)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(airline_tweets_train.target_names[airline_tweets_train.target[i]])\n",
    "\n",
    "\n",
    "print(\"VADER on the set of airline tweets with only nouns and after having lemmatized the text Classification Report\")\n",
    "print(classification_report(gold, all_vader_output))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run vader on the set of airline tweets with only verbs\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "for i, tweet in enumerate(airline_tweets_train.data[:100]):\n",
    "    vader_output = run_vader(tweet.decode('utf-8'), parts_of_speech_to_consider={'VERB'})\n",
    "    vader_label = vader_output_to_label(vader_output)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(airline_tweets_train.target_names[airline_tweets_train.target[i]])\n",
    "\n",
    "\n",
    "print(\"VADER on the set of airline tweets with only verbs Classification Report\")\n",
    "print(classification_report(gold, all_vader_output))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run vader on the set of airline tweets with only verbs and after having lemmatized the text\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "for i, tweet in enumerate(airline_tweets_train.data[:100]):\n",
    "    vader_output = run_vader(tweet.decode('utf-8'), parts_of_speech_to_consider={'VERB'}, lemmatize=True)\n",
    "    vader_label = vader_output_to_label(vader_output)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(airline_tweets_train.target_names[airline_tweets_train.target[i]])\n",
    "\n",
    "\n",
    "print(\"VADER on the set of airline tweets with only verbs and after having lemmatized the text Classification Report\")\n",
    "print(classification_report(gold, all_vader_output))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "b. Compare the scores and explain what they tell you.\n",
    "* - Does lemmatisation help? Explain why or why not.\n",
    "* - Are all parts of speech equally important for sentiment analysis? Explain why or why not."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: scikit-learn assignments\n",
    "### [4 points] Question 5\n",
    "Train the scikit-learn classifier (Naive Bayes) using the airline tweets.\n",
    "\n",
    "+ Train the model on the airline tweets with 80% training and 20% test set and default settings (TF-IDF representation, min_df=2)\n",
    "+ Train with different settings:\n",
    "    + with respect to vectorizing: TF-IDF ('airline_tfidf') vs. Bag of words representation ('airline_count') \n",
    "    + with respect to the frequency threshold (min_df). Carry out experiments with increasing values for document frequency (min_df = 2; min_df = 5; min_df =10) \n",
    "* [1 point] a. Generate a classification_report for all experiments\n",
    "* [3 points] b. Look at the results of the experiments with the different settings and try to explain why they differ: \n",
    "    + which category performs best, is this the case for any setting?\n",
    "    + does the frequency threshold affect the scores? Why or why not according to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "airline_vec = CountVectorizer(min_df=2, # If a token appears fewer times than this, across all documents, it will be ignored\n",
    "                             tokenizer=nltk.word_tokenize, # we use the nltk tokenizer\n",
    "                             stop_words=stopwords.words('english')) # stopwords are removed\n",
    "#  bag of words representation of the airline tweets\n",
    "airline_counts = airline_vec.fit_transform(airline_tweets_train.data)\n",
    "\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    airline_counts, # the tf-idf model\n",
    "    airline_tweets_train.target, # the category values for each tweet\n",
    "    test_size = 0.20 # we use 80% for training and 20% for development\n",
    "    )\n",
    "\n",
    "clf = MultinomialNB().fit(docs_train, y_train)\n",
    "y_pred = clf.predict(docs_test)\n",
    "\n",
    "print(\"Classification report for the Naive Bayes classifier on the airline tweets with 80% training and 20% test set and default settings (TF-IDF representation, min_df=2)\")\n",
    "print(classification_report(y_test, y_pred, target_names=airline_tweets_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TF-IDF representation of the airline tweets\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "airline_tfidf = tfidf_transformer.fit_transform(airline_counts)\n",
    "docs_train2, docs_test2, y_train2, y_test2 = train_test_split(\n",
    "    airline_tfidf, # the tf-idf model\n",
    "    airline_tweets_train.target, # the category values for each tweet\n",
    "    test_size = 0.20 # we use 80% for training and 20% for development\n",
    "    )\n",
    "clf2 = MultinomialNB().fit(docs_train2, y_train2)\n",
    "y_pred2 = clf2.predict(docs_test2)\n",
    "\n",
    "print(\"Classification report for the Naive Bayes classifier on the airline tweets with 80% training and 20% test set and default settings (TF-IDF representation, min_df=2)\")\n",
    "print(classification_report(y_test2, y_pred2, target_names=airline_tweets_train.target_names))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TF-IDF representation of the airline tweets with min_df=5\n",
    "airline_vec = CountVectorizer(min_df=5, # If a token appears fewer times than this, across all documents, it will be ignored\n",
    "                             tokenizer=nltk.word_tokenize, # we use the nltk tokenizer\n",
    "                             stop_words=stopwords.words('english')) # stopwords are removed\n",
    "#  bag of words representation of the airline tweets\n",
    "airline_counts = airline_vec.fit_transform(airline_tweets_train.data)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "airline_tfidf = tfidf_transformer.fit_transform(airline_counts)\n",
    "docs_train3, docs_test3, y_train3, y_test3 = train_test_split(\n",
    "    airline_tfidf, # the tf-idf model\n",
    "    airline_tweets_train.target, # the category values for each tweet\n",
    "    test_size = 0.20 # we use 80% for training and 20% for development\n",
    "    )\n",
    "clf3 = MultinomialNB().fit(docs_train3, y_train3)\n",
    "y_pred3 = clf3.predict(docs_test3)\n",
    "\n",
    "print(\"Classification report for the Naive Bayes classifier on the airline tweets with 80% training and 20% test set and default settings (TF-IDF representation, min_df=5)\")\n",
    "print(classification_report(y_test3, y_pred3, target_names=airline_tweets_train.target_names))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TF-IDF representation of the airline tweets with min_df=10\n",
    "airline_vec = CountVectorizer(min_df=10, # If a token appears fewer times than this, across all documents, it will be ignored\n",
    "                             tokenizer=nltk.word_tokenize, # we use the nltk tokenizer\n",
    "                             stop_words=stopwords.words('english')) # stopwords are removed\n",
    "#  bag of words representation of the airline tweets\n",
    "airline_counts = airline_vec.fit_transform(airline_tweets_train.data)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "airline_tfidf = tfidf_transformer.fit_transform(airline_counts)\n",
    "docs_train4, docs_test4, y_train4, y_test4 = train_test_split(\n",
    "    airline_tfidf, # the tf-idf model\n",
    "    airline_tweets_train.target, # the category values for each tweet\n",
    "    test_size = 0.20 # we use 80% for training and 20% for development\n",
    "    )\n",
    "clf4 = MultinomialNB().fit(docs_train4, y_train4)\n",
    "y_pred4 = clf4.predict(docs_test4)\n",
    "\n",
    "print(\"Classification report for the Naive Bayes classifier on the airline tweets with 80% training and 20% test set and default settings (TF-IDF representation, min_df=10)\")\n",
    "print(classification_report(y_test4, y_pred4, target_names=airline_tweets_train.target_names))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* [3 points] b. Look at the results of the experiments with the different settings and try to explain why they differ:\n",
    "    + which category performs best, is this the case for any setting?\n",
    "    + does the frequency threshold affect the scores? Why or why not according to you?\n",
    "\n",
    "Answer:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4 points] Question 6: Inspecting the best scoring features \n",
    "\n",
    "+ Train the scikit-learn classifier (Naive Bayes) model with the following settings (airline tweets 80% training and 20% test;  Bag of words representation ('airline_count'), min_df=2)\n",
    "* [1 point] a. Generate the list of best scoring features per class (see function **important_features_per_class** below) [1 point]\n",
    "* [3 points] b. Look at the lists and consider the following issues: \n",
    "    + [1 point] Which features did you expect for each separate class and why?\n",
    "    + [1 point] Which features did you not expect and why ? \n",
    "    + [1 point] The list contains all kinds of words such as names of airlines, punctuation, numbers and content words (e.g., 'delay' and 'bad'). Which words would you remove or keep when trying to improve the model and why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features_per_class(vectorizer,classifier,n=80):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names =vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.feature_count_[0], feature_names),reverse=True)[:n]\n",
    "    topn_class2 = sorted(zip(classifier.feature_count_[1], feature_names),reverse=True)[:n]\n",
    "    topn_class3 = sorted(zip(classifier.feature_count_[2], feature_names),reverse=True)[:n]\n",
    "    print(\"Important words in negative documents\")\n",
    "    for coef, feat in topn_class1:\n",
    "        print(class_labels[0], coef, feat)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in neutral documents\")\n",
    "    for coef, feat in topn_class2:\n",
    "        print(class_labels[1], coef, feat) \n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in positive documents\")\n",
    "    for coef, feat in topn_class3:\n",
    "        print(class_labels[2], coef, feat) \n",
    "\n",
    "# example of how to call from notebook:\n",
    "\n",
    "airline_vec = CountVectorizer(min_df=2, # If a token appears fewer times than this, across all documents, it will be ignored\n",
    "                             tokenizer=nltk.word_tokenize, # we use the nltk tokenizer\n",
    "                             stop_words=stopwords.words('english')) # stopwords are removed\n",
    "#  bag of words representation of the airline tweets\n",
    "airline_counts = airline_vec.fit_transform(airline_tweets_train.data)\n",
    "\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    airline_counts, # the bag of words model\n",
    "    airline_tweets_train.target, # the category values for each tweet\n",
    "    test_size = 0.20 # we use 80% for training and 20% for development\n",
    "    )\n",
    "\n",
    "clf = MultinomialNB().fit(docs_train, y_train)\n",
    "y_pred = clf.predict(docs_test)\n",
    "important_features_per_class(airline_vec, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional! (will not  be graded)] Question 7\n",
    "Train the model on airline tweets and test it on your own set of tweets\n",
    "+ Train the model with the following settings (airline tweets 80% training and 20% test;  Bag of words representation ('airline_count'), min_df=2)\n",
    "+ Apply the model on your own set of tweets and generate the classification report\n",
    "* [1 point] a. Carry out a quantitative analysis.\n",
    "* [1 point] b. Carry out an error analysis on 10 correctly and 10 incorrectly classified tweets and discuss them\n",
    "* [2 points] c. Compare the results (cf. classification report) with the results obtained by VADER on the same tweets and discuss the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional! (will not be graded)] Question 8: trying to improve the model\n",
    "* [2 points] a. Think of some ways to improve the scikit-learn Naive Bayes model by playing with the settings or applying linguistic preprocessing (e.g., by filtering on part-of-speech, or removing punctuation). Do not change the classifier but continue using the Naive Bayes classifier. Explain what the effects might be of these other settings \n",
    "+ [1 point] b. Apply the model with at least one new setting (train on the airline tweets using 80% training, 20% test) and generate the scores\n",
    "* [1 point] c. Discuss whether the model achieved what you expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "text-mining",
   "language": "python",
   "display_name": "Text-Mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}